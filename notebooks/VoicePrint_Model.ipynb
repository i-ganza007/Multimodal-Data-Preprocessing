{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmNOfiFRIdIARIlgs6ZfJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i-ganza007/Multimodal-Data-Preprocessing/blob/main/notebooks/VoicePrint_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "yvJcA255jvmR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import joblib\n",
        "import librosa\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Loading and preprocessing the data\n",
        "def load_and_preprocess_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Filter for Eddy and Lievin with commands \"yes approve\" or \"confirm transaction\"\n",
        "    valid_speakers = ['eddy', 'lievin']\n",
        "    valid_commands = ['yes approve', 'confirm transaction']\n",
        "    df = df[df['speaker'].isin(valid_speakers) & df['command'].isin(valid_commands)]\n",
        "\n",
        "    # Selecting feature columns (excluding non-feature columns like file, speaker, command)\n",
        "    feature_cols = [col for col in df.columns if col not in ['file', 'speaker', 'command', 'duration']]\n",
        "    X = df[feature_cols].values\n",
        "    y = df['speaker'].values\n",
        "\n",
        "    # Handling potential NaN or infinite values\n",
        "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    print(\"Warning: Dataset is small ({} samples). Consider adding more data for better model performance.\".format(len(X)))\n",
        "\n",
        "    return X, y, feature_cols\n"
      ],
      "metadata": {
        "id": "i_GWftZhkNPK"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_voiceprint_model(X, y):\n",
        "    # Scaling the features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Training an SVM classifier\n",
        "    model = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "    model.fit(X_scaled, y)\n",
        "\n",
        "    # Compute cross-validation metrics (2-fold CV for 4 samples)\n",
        "    metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "    print(\"\\nCross-Validation Metrics (2-fold):\")\n",
        "    for metric in metrics:\n",
        "        scores = cross_val_score(model, X_scaled, y, cv=2, scoring=metric)\n",
        "        print(f\"{metric.capitalize():<15}: {scores.mean():.4f} (Â±{scores.std():.4f})\")\n",
        "\n",
        "    print(\"Model trained on full dataset (no train-test split due to small size).\")\n",
        "\n",
        "    return model, scaler"
      ],
      "metadata": {
        "id": "dgMN_dKrkVUW"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_and_scaler(model, scaler, model_path='voiceprint_model.pkl', scaler_path='scaler.pkl'):\n",
        "    joblib.dump(model, model_path)\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "    print(f\"Scaler saved to {scaler_path}\")"
      ],
      "metadata": {
        "id": "_QCjcatElYIY"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_speaker(model, scaler, features):\n",
        "    features_scaled = scaler.transform([features])\n",
        "    probabilities = model.predict_proba(features_scaled)[0]\n",
        "    # Select the speaker with the highest probability\n",
        "    max_prob_idx = np.argmax(probabilities)\n",
        "    predicted_speaker = model.classes_[max_prob_idx]\n",
        "    return predicted_speaker, probabilities"
      ],
      "metadata": {
        "id": "VHLmmiK5kXMX"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_features(audio_file, feature_cols, sr=22050):\n",
        "    try:\n",
        "        # Load audio file\n",
        "        y, sr = librosa.load(audio_file, sr=sr)\n",
        "\n",
        "        # Check duration (proxy for valid command, based on CSV durations ~2-3 seconds)\n",
        "        duration = librosa.get_duration(y=y, sr=sr)\n",
        "        if not (1.5 <= duration <= 3.5):\n",
        "            print(f\"Error: Audio duration {duration:.2f}s is outside expected range (1.5-3.5s).\")\n",
        "            return None\n",
        "\n",
        "        # Initialize feature vector\n",
        "        features = []\n",
        "\n",
        "        # Extract MFCC features (mean and std for 13 coefficients)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        mfcc_std = np.std(mfcc, axis=1)\n",
        "        features.extend(mfcc_mean)\n",
        "        features.extend(mfcc_std)\n",
        "\n",
        "        # Extract MFCC deltas\n",
        "        mfcc_delta = librosa.feature.delta(mfcc)\n",
        "        mfcc_delta_mean = np.mean(mfcc_delta, axis=1)\n",
        "        features.extend(mfcc_delta_mean)\n",
        "\n",
        "        # Extract MFCC delta2\n",
        "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "        mfcc_delta2_mean = np.mean(mfcc_delta2, axis=1)\n",
        "        features.extend(mfcc_delta2_mean)\n",
        "\n",
        "        # Extract spectral rolloff\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        rolloff_mean = np.mean(rolloff)\n",
        "        rolloff_std = np.std(rolloff)\n",
        "        features.extend([rolloff_mean, rolloff_std])\n",
        "\n",
        "        # Extract spectral centroid\n",
        "        centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        centroid_mean = np.mean(centroid)\n",
        "        centroid_std = np.std(centroid)\n",
        "        features.extend([centroid_mean, centroid_std])\n",
        "\n",
        "        # Extract spectral bandwidth\n",
        "        bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        bandwidth_mean = np.mean(bandwidth)\n",
        "        bandwidth_std = np.std(bandwidth)\n",
        "        features.extend([bandwidth_mean, bandwidth_std])\n",
        "\n",
        "        # Extract spectral contrast\n",
        "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "        contrast_mean = np.mean(contrast)\n",
        "        contrast_std = np.std(contrast)\n",
        "        features.extend([contrast_mean, contrast_std])\n",
        "\n",
        "        # Extract spectral flatness\n",
        "        flatness = librosa.feature.spectral_flatness(y=y)\n",
        "        flatness_mean = np.mean(flatness)\n",
        "        flatness_std = np.std(flatness)\n",
        "        features.extend([flatness_mean, flatness_std])\n",
        "\n",
        "        # Extract RMS\n",
        "        rms = librosa.feature.rms(y=y)\n",
        "        rms_mean = np.mean(rms)\n",
        "        rms_std = np.std(rms)\n",
        "        features.extend([rms_mean, rms_std])\n",
        "\n",
        "        # Extract zero-crossing rate\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        zcr_mean = np.mean(zcr)\n",
        "        zcr_std = np.std(zcr)\n",
        "        features.extend([zcr_mean, zcr_std])\n",
        "\n",
        "        # Extract fundamental frequency (f0) using pyin\n",
        "        f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=50, fmax=500)\n",
        "        f0_mean = np.mean(f0[voiced_flag]) if np.any(voiced_flag) else 0.0\n",
        "        f0_std = np.std(f0[voiced_flag]) if np.any(voiced_flag) else 0.0\n",
        "        f0_min = np.min(f0[voiced_flag]) if np.any(voiced_flag) else 50.0\n",
        "        f0_max = np.max(f0[voiced_flag]) if np.any(voiced_flag) else 500.0\n",
        "        features.extend([f0_mean, f0_std, f0_min, f0_max])\n",
        "\n",
        "        # Extract LPC coefficients (assuming 12 coefficients as per CSV)\n",
        "        lpc_coeffs = librosa.lpc(y, order=11)\n",
        "        features.extend(lpc_coeffs)\n",
        "\n",
        "        # Ensure feature vector matches the expected number of features\n",
        "        features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        if len(features) != len(feature_cols):\n",
        "            raise ValueError(f\"Extracted {len(features)} features, but model expects {len(feature_cols)} features.\")\n",
        "\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "qr-GKaxqkydp"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5b83153"
      },
      "source": [
        "def test_new_audio(audio_file, model, scaler, feature_cols, confidence_threshold=0.6):\n",
        "    # Extract features from the new audio\n",
        "    features = extract_audio_features(audio_file, feature_cols)\n",
        "    if features is None:\n",
        "        return None, None, \"Rejected: Invalid audio file or feature extraction failed.\"\n",
        "\n",
        "    # Predict speaker\n",
        "    predicted_speaker, probabilities = predict_speaker(model, scaler, features)\n",
        "    max_probability = np.max(probabilities)\n",
        "\n",
        "    # Rejection clause: Check confidence threshold\n",
        "    if max_probability < confidence_threshold:\n",
        "        return None, None, f\"Rejected: Prediction confidence ({max_probability:.3f}) below threshold ({confidence_threshold}).\"\n",
        "\n",
        "    return predicted_speaker, dict(zip(model.classes_, probabilities)), \"Accepted: Command validated by duration.\""
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Path to the CSV file (replace with actual path or use loadFileData in deployment)\n",
        "    csv_file = 'audio_features(1)(1).csv'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    X, y, feature_cols = load_and_preprocess_data(csv_file)\n",
        "\n",
        "    # Train the model and compute metrics\n",
        "    model, scaler = train_voiceprint_model(X, y)\n",
        "\n",
        "    # Save the model and scaler\n",
        "    save_model_and_scaler(model, scaler)\n",
        "\n",
        "    # Example prediction (using a sample from the dataset for demonstration)\n",
        "    sample_features = X[0]  # First row as an example\n",
        "    predicted_speaker, probs = predict_speaker(model, scaler, sample_features)\n",
        "    max_prob = np.max(probs)\n",
        "    print(f\"\\nExample Prediction:\")\n",
        "    print(f\"Predicted Speaker: {predicted_speaker}\")\n",
        "    print(f\"Probabilities: {dict(zip(model.classes_, probs))}\")\n",
        "    print(f\"Status: {'Accepted' if max_prob >= 0.6 else 'Rejected: Low confidence'}\")\n",
        "\n",
        "    # Example testing a new audio file (replace with actual audio file path)\n",
        "    test_audio_file = '/content/ian_test.wav'  # Replace with actual path\n",
        "    print(f\"\\nTesting new audio file: {test_audio_file}\")\n",
        "    predicted_speaker, probabilities, status = test_new_audio(test_audio_file, model, scaler, feature_cols)\n",
        "    print(f\"Status: {status}\")\n",
        "    if predicted_speaker is not None:\n",
        "        print(f\"Predicted Speaker: {predicted_speaker}\")\n",
        "        print(f\"Probabilities: {probabilities}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA_4SerOwvPL",
        "outputId": "3af0dffa-1959-43ae-f112-823fb3a2174f"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Dataset is small (4 samples). Consider adding more data for better model performance.\n",
            "\n",
            "Cross-Validation Metrics (2-fold):\n",
            "Accuracy       : 0.7500 (Â±0.2500)\n",
            "Precision_macro: 0.6250 (Â±0.3750)\n",
            "Recall_macro   : 0.7500 (Â±0.2500)\n",
            "F1_macro       : 0.6667 (Â±0.3333)\n",
            "Model trained on full dataset (no train-test split due to small size).\n",
            "Model saved to voiceprint_model.pkl\n",
            "Scaler saved to scaler.pkl\n",
            "\n",
            "Example Prediction:\n",
            "Predicted Speaker: lievin\n",
            "Probabilities: {'eddy': np.float64(0.10201128376775633), 'lievin': np.float64(0.8979887162322437)}\n",
            "Status: Accepted\n",
            "\n",
            "Testing new audio file: /content/ian_test.wav\n",
            "Status: Rejected: Prediction confidence (0.572) below threshold (0.6).\n"
          ]
        }
      ]
    }
  ]
}